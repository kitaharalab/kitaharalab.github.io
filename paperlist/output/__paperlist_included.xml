<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="paperlist.xsl" ?>
<!DOCTYPE paperlist SYSTEM "paperlist.dtd">
<paperlist xmlns:xi="http://www.w3.org/2001/XInclude" lang="jp" myname="北原 鉄朗" myname-e="Tetsuro Kitahara">
  <authorlist>
    <author-item id="kitahara-jp" aff="KU-jp" me="yes">北原 鉄朗</author-item><author-item id="kitahara-en" aff="KU-en" me="yes">Tetsuro Kitahara</author-item><author-item id="goto-jp" aff="JST-AIST-jp" href="http://staff.aist.go.jp/m.goto/index-j.html">後藤 真孝</author-item><author-item id="goto-en" aff="JST-AIST-en" href="http://staff.aist.go.jp/m.goto/">Masataka Goto</author-item><author-item id="goto2-jp" aff="AIST-jp" href="http://staff.aist.go.jp/m.goto/index-j.html">後藤
      真孝</author-item><author-item id="goto2-en" aff="AIST-en" href="http://staff.aist.go.jp/m.goto/">Masataka Goto</author-item><author-item id="okuno-jp" aff="KU-jp" href="http://winnie.kuis.kyoto-u.ac.jp/~okuno/">奥乃 博</author-item><author-item id="okuno-en" aff="KU-en" href="http://winnie.kuis.kyoto-u.ac.jp/~okuno/">Hiroshi
      G. Okuno</author-item><author-item id="ogata-jp" aff="KU-jp" href="http://winnie.kuis.kyoto-u.ac.jp/~ogata/index_j.html">尾形 哲也</author-item><author-item id="ogata-en" aff="KU-en" href="http://winnie.kuis.kyoto-u.ac.jp/~ogata/">Tetsuya
      Ogata</author-item><author-item id="komatani-jp" aff="KU-jp" href="http://winnie.kuis.kyoto-u.ac.jp/~komatani/">駒谷
      和範</author-item><author-item id="komatani-en" aff="KU-en" href="http://winnie.kuis.kyoto-u.ac.jp/~komatani/">Kazunori Komatani</author-item><author-item id="sakuraba-jp" aff="KU-jp" href="http://winnie.kuis.kyoto-u.ac.jp/~sakuraba/">櫻庭
      洋平</author-item><author-item id="sakuraba-en" aff="KU-en" href="http://winnie.kuis.kyoto-u.ac.jp/~sakuraba/">Yohei Sakuraba</author-item><author-item id="fujihara-jp" aff="KU-jp" href="http://winnie.kuis.kyoto-u.ac.jp/~fujihara/">藤原
      弘将</author-item><author-item id="fujihara-en" aff="KU-en" href="http://winnie.kuis.kyoto-u.ac.jp/~fujihara/">Hiromasa Fujihara</author-item><author-item id="ishida-jp" aff="TUS-jp" href="http://issoft0.is.noda.tus.ac.jp/~kdi/">石田 克久</author-item><author-item id="ishida-en" aff="TUS-en" href="http://issoft0.is.noda.tus.ac.jp/~kdi/">Katsuhisa
      Ishida</author-item><author-item id="takeda-jp" aff="TUS-jp" href="http://issoft0.is.noda.tus.ac.jp/~takeda/">武田 正之</author-item><author-item id="takeda-en" aff="TUS-en" href="http://issoft0.is.noda.tus.ac.jp/~takeda/">Masayuki Takeda</author-item><author-item id="kitahara2-jp" aff="CrestMuse-Kwansei-jp" me="yes">北原 鉄朗</author-item><author-item id="kitahara2-en" aff="CrestMuse-Kwansei-en" me="yes">Tetsuro Kitahara</author-item><author-item id="katayose-jp" aff="CrestMuse-Kwansei-jp" href="http://ist.ksc.kwansei.ac.jp/~katayose/intro.html">片寄 晴弘</author-item><author-item id="katayose-en" aff="CrestMuse-Kwansei-en" href="http://ist.ksc.kwansei.ac.jp/~katayose/intro.html">Haruhiro Katayose</author-item><author-item id="kitahara3-jp" aff="NU-jp" me="yes">北原 鉄朗</author-item><author-item id="kitahara3-en" aff="NU-en" me="yes">Tetsuro Kitahara</author-item>
  </authorlist>
  <afflist>
    <aff-item id="KU-jp">京都大学大学院情報学研究科知能情報学専攻</aff-item><aff-item id="KU-en">Dept. of Intelligence Science and Technology, Graduate School of
      Informatics, Kyoto University</aff-item><aff-item id="JST-AIST-jp">科学技術振興事業団さきがけ研究21「情報と知」領域 ／産業技術総合研究所</aff-item><aff-item id="JST-AIST-en"> "Information and Human Activity", PRESTO, JST / National Institute
      of Advanced Industrial Science &amp; Technology (AIST)</aff-item><aff-item id="AIST-jp">産業技術総合研究所</aff-item><aff-item id="AIST-en"> National Institute of Advanced Industrial Science &amp; Technology
      (AIST)</aff-item><aff-item id="TUS-jp">東京理科大学大学院理工学研究科情報科学専攻</aff-item><aff-item id="TUS-en">Dept. of Information Sciences, Tokyo University of Science</aff-item><aff-item id="CrestMuse-Kwansei-jp">科学技術新興機構戦略的創造研究推進事業CrestMuseプロジェクト／関西学院大学理工学研究科</aff-item><aff-item id="CrestMuse-Kwansei-en">CrestMuse Project, CREST, JST / Graduate School of Science
    and Technology, Kwansei Gakuin University</aff-item><aff-item id="NU-jp">日本大学文理学部情報システム解析学科</aff-item><aff-item id="NU-en">College of Humanities and Sciences, Nihon University</aff-item>
  </afflist>
  <booktitlelist>
    <book-item id="icassp2003" abbr="ICASSP 2003" href="http://www.icassp2003.org/">Proceedings of
      the 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing</book-item><book-item id="icassp2004" abbr="ICASSP 2004" href="http://www.icassp2004.org/">Proceedings of
      the 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing</book-item><book-item id="icassp2006" abbr="ICASSP 2006" href="http://www.icassp2006.org/">Proceedings of
      the 2006 IEEE International Conference on Acoustics, Speech, and Signal Processing</book-item><book-item id="ismir2004" abbr="ISMIR 2004" href="http://ismir2004.ismir.net/">Proceedings of
      the 5th International Conference on Music Information Retrieval</book-item><book-item id="ismir2005" abbr="ISMIR 2005" href="http://ismir2005.ismir.net/">Proceedings of
      the 6th International Conference on Music Information Retrieval </book-item><book-item id="ismir2006" abbr="ISMIR 2006" href="http://ismir2006.ismir.net/">Proceedings of
      the 7th International Conference on Music Information Retrieval </book-item><book-item id="ismir2008" abbr="ISMIR 2008" href="http://ismir2008.ismir.net/">Proceedings of
      the 9th International Conference on Music Information Retrieval </book-item><book-item id="icslp2006" abbr="ICSLP 2006">Proceedings of the International Conference on
      Spoken Language Processing</book-item><book-item id="icme2003" abbr="ICME 2003">Proceedings of the 2003 IEEE International Conference
      on Multimedia &amp; Expo</book-item><book-item id="isma2004" abbr="ISMA 2004">Proceedings of the 2004 International Symposium on
      Musical Acoustics</book-item><book-item id="nime2004" abbr="NIME 2004">Proceedings of the International Conference on New
      Interfaces for Musical Expression </book-item><book-item id="sigmus">情報処理学会 音楽情報科学 研究報告</book-item><book-item id="ipsjnc2001">情報処理学会 第62回全国大会</book-item><book-item id="ipsjnc2002">情報処理学会 第64回全国大会</book-item><book-item id="ipsjnc2003">情報処理学会 第65回全国大会</book-item><book-item id="ipsjnc2004">情報処理学会 第66回全国大会</book-item><book-item id="ipsjnc2005">情報処理学会 第67回全国大会</book-item><book-item id="ipsjnc2006">情報処理学会 第68回全国大会</book-item><book-item id="ipsjnc2007">情報処理学会 第69回全国大会</book-item><book-item id="ipsjnc2008">情報処理学会 第70回全国大会</book-item><book-item id="asj2002a">日本音響学会2002年秋季研究発表会 講演論文集</book-item><book-item id="asj2004a">日本音響学会2004年秋季研究発表会 講演論文集</book-item><book-item id="asj2005a">日本音響学会2005年秋季研究発表会 講演論文集</book-item><book-item id="asj2006s">日本音響学会2006年春季研究発表会 講演論文集</book-item><book-item id="asj2006a">日本音響学会2006年秋季研究発表会 講演論文集</book-item><book-item id="asj2007a">日本音響学会2007年秋季研究発表会 講演論文集</book-item><book-item id="asj2008a">日本音響学会2008年秋季研究発表会 講演論文集</book-item><book-item id="si2005" abbr="SI 2005">計測自動制御学会 第6回システムインテグレーション部門講演会</book-item><book-item id="ism2006" abbr="ISM 2006">Proceesings of the 8th IEEE International Symposium on
      Multimedia</book-item><book-item id="masp2008" abbr="ISM 2008 MASP Workshop" href="">Proceesings of the 10th IEEE
      International Symposium on Multimedia, Workshop on Multimedia Audio and Speech Processing</book-item><book-item id="wiss2003" abbr="WISS 2003">Proceedings of the 11th Workshop on Interactive
      Systems and Software</book-item><book-item id="wiss2004" abbr="WISS 2004">Proceedings of the 12th Workshop on Interactive
      Systems and Software</book-item><book-item id="wiss2005" abbr="WISS 2005">Proceedings of the 13th Workshop on Interactive
      Systems and Software</book-item><book-item id="ec2007" abbr="EC2007" href="http://ec2007.entcomp.org/">Proceedings of
      Entertainment Computing 2007</book-item><book-item id="icmpc2008" abbr="ICMPC 2008">Proceedings of the 10th International Conference on
      Music Perception and Cognition</book-item><book-item id="jsai2008">第22回人工知能学会全国大会</book-item>
  </booktitlelist>

  <item type="dc" id="KitaharaIPSJNC2001" lang="jp">
    <title>楽器音オントロジー作成のための楽器音特徴抽出</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2001"/>
    <series>4M-5</series>
    <month>3</month>
    <year>2001</year>
  </item><item type="dt" id="KitaharaSIGMUS2001" lang="jp">
    <title>音高による音色変化に着目した音源同定手法</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2001-MUS-40-2</series>
    <vol>2001</vol>
    <no>45</no>
    <pp>7--14</pp>
    <month>5</month>
    <year>2001</year>
  </item><item type="dc" id="YanagawaIPSJNC2002" lang="jp">
    <title>即興演奏における演奏補正システム</title>
    <authors>
      <author>柳川 貴央</author>
      <author idref="kitahara-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle idref="ipsjnc2002"/>
    <series>1L-5</series>
    <month>3</month>
    <year>2002</year>
  </item><item type="dt" id="KitaharaSIGMUS2002" lang="jp">
    <title>楽器音を対象とした音源同定：音高による音色変化を考慮する識別手法の検討</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2002-MUS-46-1</series>
    <vol>2002</vol>
    <no>63</no>
    <pp>1--8</pp>
    <month>7</month>
    <year>2002</year>
  </item><item type="dc" id="KitaharaASJ2002" lang="jp">
    <title>音色空間の音高依存性を考慮した楽器音の音源同定</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="asj2002a"/>
    <series>1-1-4</series>
    <pp>643--644</pp>
    <month>9</month>
    <year>2002</year>
    <slideurl type="pdf">FY2002/asj-2002-tetsu.pdf</slideurl>
  </item><item type="dc" id="KitaharaIPSJNC2003" lang="jp">
    <title>音響的類似性に基づく楽器音の階層的クラスタリング</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2002"/>
    <series>1P-1</series>
    <month>3</month>
    <year>2003</year>
    <award shortened="yes">学生奨励賞</award>
  </item><item type="dc" id="YoshiiIPSJNC2003" lang="jp">
    <title>教師なしクラスタリングと認識誤りパターンを利用した打楽器音の音源同定</title>
    <authors>
      <author>吉井 和佳</author>
      <author idref="kitahara-jp"/>
      <author idref="sakuraba-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2002"/>
    <series>1P-3</series>
    <month>3</month>
    <year>2003</year>
  </item><item type="dc" id="IshidaIPSJNC2003" lang="jp">
    <title>統計的アプローチに基づく即興演奏補正</title>
    <authors>
      <author idref="ishida-jp"/>
      <author idref="kitahara-jp"/>
      <author>柳川 貴央</author>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2002"/>
    <series>1P-3</series>
    <month>3</month>
    <year>2003</year>
  </item><item type="ic" id="KitaharaICASSP2003" lang="en">
    <title>Musical Instrument Identification based on F0-dependent Multivariate Normal Distribution</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="icassp2003"/>
    <vol>V</vol>
    <pp>421--424</pp>
    <month>4</month>
    <year>2003</year>
    <abst> The <em>pitch dependency</em> of timbres has not been fully exploited in musical
      instrument identification. In this paper, we present a method using an <em>F0-dependent
        multivariate normal distribution</em> of which mean is represented by a function of
      fundamental frequency (F0). This F0-dependent mean function represents the pitch dependency of
      each feature, while the F0-normalized covariance represents the non-pitch dependency. Musical
      instrument sounds are first analyzed by the F0-dependent multivariate normal distribution, and
      then identified by using the discriminant function based on the Bayes decision rule.
      Experimental results of identifying 6,247 solo tones of 19 musical instruments by 10-fold
      cross validation showed that the proposed method improved the recognition rate at
      individual-instrument level from 75.73% to 79.73%, and the recognition rate at category level
      from 88.20% to 90.65%. </abst>
    <paperurl type="pdf">FY2003/icassp-2003-tetsu.pdf</paperurl>
    <note>Cancelled because of SARS</note>
  </item><item type="ln" id="KitaharaIEAAIE2003" lang="en">
    <title>Pitch-dependent Musical Instrument Identification and Its Application to Musical Sound
      Ontology</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle>Developments in Applied Artificial Intelligence --- Proceedings of the 16th
      International Conference on Industrial Engineering Applications of Artificial Intelligence and
      Expert Systems (IEA/AIE-2003)</booktitle>
    <series>LNAI 2718</series>
    <eds>P. W. H. Chung, C. Hinde and M. Ali</eds>
    <pp>112--122</pp>
    <pub>Springer</pub>
    <month>7</month>
    <year>2003</year>
  </item><item type="ic" id="KitaharaICME2003" lang="en">
    <title>Musical Instrument Identification based on F0-dependent Multivariate Normal Distribution</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="icme2003"/>
    <vol>III</vol>
    <pp>409--412</pp>
    <month>7</month>
    <year>2003</year>
    <posterurl type="pdf">icme-2004-tetsu_bigsize.pdf</posterurl>
    <note>Reprint of the paper published in ICASSP 2003</note>
  </item><item type="jj" id="KitaharaIPSJ2003" lang="jp">
    <title>音高による音色変化に着目した楽器音の音源同定：F0依存多次元正規分布に基づく識別手法</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle>情報処理学会論文誌</booktitle>
    <vol>44</vol>
    <no>10</no>
    <pp>2448--2458</pp>
    <month>10</month>
    <year>2003</year>
    <abst>
      本論文では，音高による音色変化を考慮する楽器音の音源同定手法を提案する．楽器音の音色が音高によって変化することは，従来から広く知られているにも関わらず，これを適切に扱える音源同定手法については，研究されてこなかった．本論文では，音高による音色変化を適切に扱うため，平均が基本周波数によって変化する多次元正規分布を提案する．そして，音色空間（楽器音の特徴空間）上で各楽器音データがこの分布に従うと仮定し，この分布のための識別関数をベイズ決定規則から定式化する．提案手法を実装・実験した結果，音高による音色変化を考慮しない多次元正規分布を用いた場合の誤認識全体のうち，個々の楽器レベルでは16.48\%，カテゴリーレベルでは20.67\%の誤認識を削減することができた． </abst>
    <paperurl type="pdf">FY2003/ipsj-2003-tetsu.pdf</paperurl>
    <award>電気通信普及財団 第19回テレコムシステム技術学生賞 受賞</award>
  </item><item type="jj" id="KitaharaIPSJ2004" lang="jp">
    <title>音響的類似性を反映した楽器の階層表現の獲得とそれに基づく未知楽器のカテゴリーレベルの音源同定</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle>情報処理学会論文誌</booktitle>
    <series>特集「音楽情報科学」</series>
    <vol>45</vol>
    <no>3</no>
    <pp>680--689</pp>
    <month>3</month>
    <year>2004</year>
    <abst>
      本論文では，音響的特徴から得られる楽器の階層表現に基づいた未知楽器（学習データに含まれない楽器）のカテゴリーレベルの音源同定について述べる．未知の楽器をどのように扱うかという問題は，楽器音の音源同定において不可避な問題であるにも関わらず，これまでの研究では扱われてこなかった．本研究では，未知の楽器をカテゴリーレベルで認識することを提案する．まず，未知楽器のカテゴリーレベルの認識に適した楽器の階層表現を自動的に獲得する手法について述べ，この手法に基づいて得られた楽器の階層表現を用いて，未知の楽器のカテゴリーレベルの認識を行う．さらに，楽器音が既知か未知か（すなわち，学習データに含まれる楽器か否か）を判定する処理を導入することで，既知の楽器は楽器名レベルで，未知の楽器はカテゴリーレベルで認識することを実現する．実験の結果，平均約77%の未知の楽器音をカテゴリーレベルで認識することができた． </abst>
    <paperurl type="pdf">FY2003/ipsj-2004-tetsu.pdf</paperurl>
  </item><item type="lt" id="IshidaIPSJ2004" lang="jp">
    <title>N-gramによる即興演奏の旋律補正</title>
    <authors>
      <author idref="ishida-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle>情報処理学会論文誌（テクニカルノート）</booktitle>
    <series>特集「音楽情報科学」</series>
    <vol>45</vol>
    <no>3</no>
    <pp>743--746</pp>
    <month>3</month>
    <year>2004</year>
    <paperurl type="pdf">FY2003/ipsj-2004-ishida.pdf</paperurl>
  </item><item type="dr" id="IshidaWISS2003" lang="jp">
    <title>ism：即興演奏の不自然な旋律を補正する演奏支援システム</title>
    <authors>
      <author idref="ishida-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle idref="wiss2003"/>
    <pp>19--24</pp>
    <month>12</month>
    <year>2003</year>
  </item><item type="dt" id="KitaharaSIGMUS2003" lang="jp">
    <title>音響的特徴に基づく楽器の階層表現の獲得とそれに基づくカテゴリーレベルの楽器音認識の検討</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2003-MUS-51-9</series>
    <vol>2003</vol>
    <no>82</no>
    <pp>51--58</pp>
    <month>8</month>
    <year>2003</year>
  </item><item type="dc" id="KitaharaIPSJNC2004" lang="jp">
    <title>未知の楽器を考慮する楽器音の音源同定</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2004"/>
    <series>3ZA-3</series>
    <month>3</month>
    <year>2004</year>
    <award shortened="yes">学生奨励賞</award>
  </item><item type="dt" id="YoshiiSIGMUS2003" lang="jp">
    <title>自己組織化マップによる教師なしクラスタリングを利用したドラム演奏の自動採譜</title>
    <authors>
      <author>吉井 和佳</author>
      <author idref="kitahara-jp"/>
      <author>櫻庭 洋平</author>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2003-MUS-51-8</series>
    <vol>2003</vol>
    <no>82</no>
    <pp>43--40</pp>
    <month>8</month>
    <year>2003</year>
  </item><item type="dt" id="GotoSIGMUS2003" lang="jp">
    <title>パネルディスカッション「音楽情報処理研究者\{に，が\}望むこと」</title>
    <authors>
      <author idref="goto-jp"/>
      <author>平田 圭二</author>
      <author idref="katayose-jp"/>
      <author>平井 重行</author>
      <author>濱中 雅俊</author>
      <author>武田 晴登</author>
      <author idref="kitahara-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2003-MUS-51-5</series>
    <vol>2003</vol>
    <no>82</no>
    <pp>25--28</pp>
    <month>8</month>
    <year>2003</year>
  </item><item type="iv">
    <title>パネルディスカッション「音楽情報処理研究者\{に，が\}望むこと」</title>
    <booktitle>情報処理学会第51回音楽情報科学研究会</booktitle>
    <series>パネリスト</series>
    <month>8</month>
    <year>2003</year>
  </item><item type="dt" id="IshidaSIGMUS2003" lang="jp">
    <title>ism：即興演奏支援のためのリアルタイム旋律補正システム</title>
    <authors>
      <author idref="ishida-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle>情報処理学会 ヒューマンインターフェース研究会/音楽情報科学研究会 研究報告</booktitle>
    <series>2003-HI-106-2, 2003-MUS-52-2</series>
    <vol>2003</vol>
    <no>111</no>
    <pp>9--15</pp>
    <month>11</month>
    <year>2003</year>
  </item><item type="dc" id="YoshiokaIPSJNC2004" lang="jp">
    <title>音楽音響信号を対象とした和音変化時刻と和音名の同時認識</title>
    <authors>
      <author>吉岡 拓也</author>
      <author>吉井 和佳</author>
      <author idref="kitahara-jp"/>
      <author idref="sakuraba-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2004"/>
    <series>3ZA-4</series>
    <month>3</month>
    <year>2004</year>
  </item><item type="ic" id="KitaharaISMA2004" lang="en">
    <title>Acoustical-similarity-based Musical Instrument Hierarchy and Its Application to Musical
      Instrument Identification</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="isma2004"/>
    <series>3-S2-12</series>
    <pp>397--300</pp>
    <month>4</month>
    <year>2004</year>
    <paperurl type="pdf">FY2004/isma-2004-tetsu.pdf</paperurl>
    <slideurl type="pdf">FY2004/isma-2004-tetsu.pdf</slideurl>
    <note>abstract reviewed</note>
  </item><item type="ic" id="KitaharaICASSP2004" lang="en">
    <title>Category-level Identification of Non-registered Musical Instrument Sounds</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="icassp2004"/>
    <vol>IV</vol>
    <pp>253--256</pp>
    <month>5</month>
    <year>2004</year>
    <abst> This paper describes a method that identifies sounds of <em>non-registered musical
        instruments </em>(i.e., musical instruments that are not contained in the training data) at
      a category level. Although the problem of how to deal with non-registered musical instruments
      is essential in musical instrument identification, it has not been dealt with in previous
      studies. Our method solves this problem by distinguishing between registered and
      non-registered instruments and identifying the category name of the non-registered
      instruments. When a given sound is registered, its instrument name, e.g. violin, is
      identified. Even if it is not registered, its category name, e.g. strings, can be identified.
      The important issue in achieving such identification is to adopt a musical instrument
      hierarchy reflecting the acoustical similarity. We present a method for acquiring such a
      hierarchy from a musical instrument sound database. Experimental results show that around 77%
      of non-registered instrument sounds, on average, were correctly identified at the category
      level. </abst>
    <paperurl type="pdf">FY2004/icassp-2004-tetsu.pdf</paperurl>
    <posterurl type="pdf">FY2004/icassp-2004-tetsu.pdf</posterurl>
  </item><item type="ic" id="SakurabaICASSP2004" lang="en">
    <title>Comparing Features for Forming Music Streams in Automatic Music Transcription</title>
    <authors>
      <author idref="sakuraba-en"/>
      <author idref="kitahara-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="icassp2004"/>
    <vol>IV</vol>
    <pp>273--376</pp>
    <month>5</month>
    <year>2004</year>
    <abst> In formating temporal sequences of notes played by the same instrument (referred to as
      music streams), timbre of musical instruments may be a predominant feature. In polyphonic
      music, the performance of timber extraction based on power-related features deteriorates,
      because such features are blurred when two or more frequency components are superimposed in
      the same frequency. To cope with this problem, we integrated timbre similarity and direction
      proximity with success, but left using other features as future work. In this paper, we
      investigate four features, timbre similarity, direction proximity, pitch transition and pitch
      relation consistency to clarify the precedence among them in music stream formation.
      Experimental results with quartet music show that direction proximity is themost dominant
      feature, and pitch transition is the secondary. In addition, the performance of music stream
      formation was improved from 63.3% by only timbre similarity to 84.9% by integrating four
      features. </abst>
    <paperurl type="pdf">FY2004/icassp-2004-sakuraba.pdf</paperurl>
  </item><item type="ic" id="IshidaNIME2004" lang="en">
    <title>ism: Improvisation Supporting System based on Melody Correction</title>
    <authors>
      <author idref="ishida-en"/>
      <author idref="kitahara-en"/>
      <author idref="takeda-en"/>
    </authors>
    <booktitle idref="nime2004"/>
    <pp>177--180</pp>
    <month>6</month>
    <year>2004</year>
    <abst> In this paper, we describe a novel improvisation supporting system based on correcting
      musically unnatural melodies. Since improvisation is the musical performance style that
      involves creating melodies while playing, it is not easy even for the people who can play
      musical instruments. However, previous studies have not dealt with improvisation support for
      the people who can play musical instruments but cannot improvise. In this study, to support
      such players' improvisation, we propose a novel improvisation supporting system called ism,
      which corrects musically unnatural melodies automatically. The main issue in realizing this
      system is how to detect notes to be corrected (i.e., musically unnatural or inappropriate). We
      propose a method for detecting notes to be corrected based on the N-gram model. This method
      first calculates N-gram probabilities of played notes, and then judges notes with low N-gram
      probabilities to be corrected. Experimental results show that the N-gram-based melody
      correction and the proposed system are useful for supporting improvisation. </abst>
    <paperurl type="pdf">FY2004/nime-2004-ishida.pdf</paperurl>
  </item><item type="ic" id="YoshiokaISMIR2004" lang="en">
    <title>Automatic Chord Transcription with Concurrent Recognition of Chord Symbols and Boundaries</title>
    <authors>
      <author aff="KU-en">Takuya Yoshioka</author>
      <author idref="kitahara-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="ismir2004"/>
    <pp>100--105</pp>
    <month>10</month>
    <year>2004</year>
    <abst> This paper describes a method that recognizes musical chords from real-world audio
      signals in compact-disc recordings. The automatic recognition of musical chords is necessary
      for music information retrieval (MIR) systems, since the chord sequences of musical pieces
      capture the characteristics of their accompaniments. None of the previous methods can
      accurately recognize musical chords from complex audio signals that contain vocal and drum
      sounds. The main problem is that the chordboundary-detection and chord-symbol-identification
      processes are inseparable because of their mutual dependency. In order to solve this mutual
      dependency problem, our method generates hypotheses about tuples of chord symbols and chord
      boundaries, and outputs the most plausible one as the recognition result. The certainty of a
      hypothesis is evaluated based on three cues: acoustic features, chord progression patterns,
      and bass sounds. Experimental results show that our method successfully recognized chords in
      seven popular music songs; the average accuracy of the results was around 77%. </abst>
  </item><item type="dr" id="IshidaWISS2004" lang="jp">
    <title>演奏者に振動で情報提示する鍵盤楽器「ぶるぶるくん」</title>
    <authors>
      <author idref="ishida-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle idref="wiss2004"/>
    <pp>59--64</pp>
    <month>12</month>
    <year>2004</year>
  </item><item type="dt" id="KitaharaMA2004" lang="jp">
    <title>TimbreTree：音色の類似度に基づいた楽器の階層的分類</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle>日本音響学会 音楽音響研究会 資料</booktitle>
    <series>MA2004-7</series>
    <vol>23</vol>
    <no>2</no>
    <pp>13--18</pp>
    <month>6</month>
    <year>2004</year>
  </item><item type="dt" id="KitaharaSIGMUS2004" lang="jp">
    <title>混合音テンプレートを用いた多重奏の音源同定</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2004-MUS-56-9</series>
    <vol>2004</vol>
    <no>84</no>
    <pp>57--64</pp>
    <month>8</month>
    <year>2004</year>
  </item><item type="dc" id="KitaharaIPSJNC2005" lang="jp">
    <title>多重奏の音源同定のための混合音からのテンプレート作成法</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2005"/>
    <series>3G-4</series>
    <month>3</month>
    <year>2005</year>
    <award shortened="yes">大会奨励賞</award>
  </item><item type="dt" id="YoshiokaMA2004" lang="jp">
    <title>音楽音響信号を対象とした和音進行の認識</title>
    <authors>
      <author>吉岡 拓也</author>
      <author idref="kitahara-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle>日本音響学会 音楽音響研究会 資料</booktitle>
    <series>MA2004-8</series>
    <vol>23</vol>
    <no>2</no>
    <pp>19--24</pp>
    <month>6</month>
    <year>2004</year>
  </item><item type="dt" id="YoshiokaSIGMUS2004" lang="jp">
    <title>和音区間検出と和音名同定の相互依存性を解決する和音認識手法</title>
    <authors>
      <author>吉岡 拓也</author>
      <author idref="kitahara-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2005-MUS-56-6</series>
    <vol>2004</vol>
    <no>84</no>
    <pp>33--40</pp>
    <month>8</month>
    <year>2004</year>
  </item><item type="dt" id="HamanakaSIGMUS2004" lang="jp">
    <title>デモンストレーション：若手による研究紹介</title>
    <authors>
      <author>浜中 雅俊</author>
      <author>北原 鉄朗</author>
      <author>石田 克久</author>
      <author>谷井 章夫</author>
      <author>竹川 佳成</author>
      <author>吉井 和佳</author>
      <author>宮下 芳明</author>
      <author>上 田 健太郎</author>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2004-MUS-56-6</series>
    <vol>2004</vol>
    <no>84</no>
    <pp>27--32</pp>
    <month>8</month>
    <year>2004</year>
  </item><item type="dt" id="HamanakaSIGMUS2005" lang="jp">
    <title>デモンストレーション：若手による研究紹介II</title>
    <authors>
      <author>浜中 雅俊</author>
      <author>李 昇姫</author>
      <author>池月 雄哉</author>
      <author>石原 一志</author>
      <author>北原 鉄朗</author>
      <author>野池 賢二</author>
      <author>中野 倫靖</author>
      <author>梶 克彦</author>
      <author>岡 良典</author>
      <author>平田 圭二</author>
      <author>松田 周</author>
      <author>青木 忍</author>
      <author>上田 健太郎</author>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2005-MUS-61-5</series>
    <vol>2005</vol>
    <no>82</no>
    <pp>27--33</pp>
    <month>8</month>
    <year>2005</year>
  </item><item type="dt" id="FujiharaSIGMUS2005" lang="jp">
    <title>伴奏音抑制と高信頼度フレーム選択に基づく楽曲中の歌声の歌手名同定手法</title>
    <authors>
      <author idref="fujihara-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2005-MUS-61-16</series>
    <vol>2005</vol>
    <no>82</no>
    <pp>97--104</pp>
    <month>8</month>
    <year>2005</year>
  </item><item type="dc" id="IshidaASJ2004a" lang="jp">
    <title>統計モデルに基づく旋律妥当性判定手法を用いた即興演奏支援</title>
    <authors>
      <author idref="ishida-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle idref="asj2004a"/>
    <series>2-6-8</series>
    <pp>783--784</pp>
    <month>9</month>
    <year>2004</year>
  </item><item type="dc" id="FujiharaIPSJNC2005" lang="jp">
    <title>歌声の調波構造抽出を用いた歌手名の同定</title>
    <authors>
      <author idref="fujihara-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2005"/>
    <series>3R-8</series>
    <month>3</month>
    <year>2005</year>
  </item><item type="jj" id="IshidaIPSJ2005" lang="jp">
    <title>N-gramによる旋律の音楽的適否判定に基づいた即興演奏支援システム</title>
    <authors>
      <author idref="ishida-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle>情報処理学会論文誌</booktitle>
    <series>特集「インタラクション：技術と展開」</series>
    <vol>46</vol>
    <no>7</no>
    <pp>1549--1559</pp>
    <month>7</month>
    <year>2005</year>
    <abst>
        本論文では，即興演奏未習得者のための演奏支援について述べる．我々の最終目標は，即興演奏未習得者が通常の楽器を用いて即興演奏を行えるようになることである．この目標を達成するために，我々は「即時的旋律創作能力の補助」と「即興演奏の練習環境の提供」の2つのアプローチで，即興演奏の未習得者をサポートする．「即時的旋律創作能力の補助」に対しては，旋律中の不適切な音を自動的に補正する演奏支援システムismを開発した．これは，演奏された旋律中の不自然な個所をリアルタイムに検出し，適切な音に変換することで，即時的な旋律創作を容易にするためのものである．「即興演奏の練習環境の提供」に対しては振動により不適切な音を指摘する学習支援システムism<sub>v</sub>を構築した．このような支援システムを実現するうえで中心となる課題は，どのように不適切な音を検出するかである．これに対し我々は，N-gramで旋律をモデル化し，その確率値が小さなもののみを不適切と判定する手法を提案する．実験の結果，提案手法により旋律中の不適切な個所の検出精度を上させることができ，ism/ism<sub>v</sub>が即興未習得者の演奏支援に有効であることが示された． </abst>
    <paperurl type="pdf">FY2005/ipsj-2005-ishida.pdf</paperurl>
  </item><item type="ic" id="KitaharaISMIR2005" lang="en">
    <title>Instrument Identification in Polyphonic Music: Feature Weighting with Mixed Sounds,
      Pitch-dependent Timbre Modeling, and Use of Musical Context</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto2-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="ismir2005"/>
    <pp>558--563</pp>
    <month>9</month>
    <year>2005</year>
    <abst> This paper addresses the problem of identifying musical instruments in polyphonic music.
      Musical instrument identification (MII) is an improtant task in music information retrieval
      because MII results make it possible to automatically retrieving certain types of music (e.g.,
      piano sonata, string quartet). Only a few studies, however, have dealt with MII in polyphonic
      music. In MII in polyphonic music, there are three issues: feature variations caused by sound
      mixtures, the pitch dependency of timbres, and the use of musical context. For the first
      issue, templates of feature vectors representing timbres are extracted from not only isolated
      sounds but also sound mixtures. Because some features are not robust in the mixtures, features
      are weighted according to their robustness by using linear discriminant analysis. For the
      second issue, we use an F0-dependent multivariate normal distribution, which approximates the
      pitch dependency as a function of fundamental frequency. For the third issue, when the
      instrument of each note is identified, the a priori probablity of the note is calculated from
      the a posteriori probabilities of temporally neighboring notes. Experimental results showed
      that recognition rates were improved from 60.8% to 85.8% for trio music and from 65.5% to
      91.1% for duo music. </abst>
    <paperurl type="pdf">FY2005/ismir-2005-tetsu.pdf</paperurl>
    <posterurl type="pdf">FY2005/ismir-2005-tetsu.pdf</posterurl>
  </item><item type="ic" id="FujiharaISMIR2005" lang="en">
    <title>Singer Identification based on Accompaniment Sound Reduction and Reliable Frame Selection</title>
    <authors>
      <author idref="fujihara-en"/>
      <author idref="kitahara-en"/>
      <author idref="goto2-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="ismir2005"/>
    <pp>329--336</pp>
    <month>9</month>
    <year>2005</year>
    <abst> This paper describes a method for automatic singer identification from polyphonic musical
      audio signals including sounds of various instruments. Because singing voices play an
      important role in musical pieces with a vocal part, the identification of singer names is
      useful for music information retrieval systems. The main problem in automatically identifying
      singers is the negative influences caused by accompaniment sounds. To solve this problem, we
      developed two methods, accompaniment sound reduction and reliable frame selection. The former
      method makes it possible to identify the singer of a singing voice after reducing
      accompaniment sounds. It first extracts harmonic components of the predominant melody from
      sound mixtures and then resynthesizes the melody by using a sinusoidal model driven by those
      components. The latter method then judges whether each frame of the obtained melody is
      reliable (i.e. little influenced by accompaniment sound) or not by using two Gaussian mixture
      models for vocal and non-vocal frames. It enables the singer identification using only
      reliable vocal portions of musical pieces. Experimental results with forty popular-music songs
      by ten singers showed that our method was able to reduce the influences of accompaniment
      sounds and achieved an accuracy of 95%, while the accuracy for a conventional method was 53%. </abst>
    <paperurl type="pdf">FY2005/ismir-2005-fujihara.pdf</paperurl>
  </item><item type="ln" id="KitaharaICEC2005" lang="en">
    <title>ism: Improvisation Supporting Systems with Melody Correction and Key Vibration</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="ishida-en"/>
      <author idref="takeda-en"/>
    </authors>
    <booktitle>Entertainment Computing --- Proceedings of the 4th International Conference on
      Entertainment Computing (ICEC 2005)</booktitle>
    <series>LNCS 3711</series>
    <eds>F. Kishino, Y. Kitamura, H. Kato and N. Nagata</eds>
    <pp>315--327</pp>
    <month>9</month>
    <year>2005</year>
    <abst> This paper describes improvisation support for musicians who do not have sufficient
      improvisational playing experience. The goal of our study is to enable such players to learn
      the skills necessary for improvisation and to enjoy it. In achieving this goal, we have two
      objectives: enhancing their skill for instantaneous melody creation and supporting their
      practice for acquiring this skill. For the first objective, we developed a system that
      automatically corrects musically inappropriate notes in the melodies of users' improvisations.
      For the second objective, we developed a system that points out musically inappropriate notes
      by vibrating corresponding keys. The main issue in developing these systems is how to detect
      musically inappropriate notes. We propose a method for detecting them based on the N-gram
      model. Experimental results show that this N-gram-based method improves the accuracy of
      detecting musically inappropriate notes and our systems are effective in supporting unskilled
      musicians' improvisation. </abst>
    <paperurl type="pdf">FY2005/icec-2005-tetsu.pdf</paperurl>
    <slideurl type="pdf">icec-2005-tetsu.pdf</slideurl>
  </item><item type="ij" id="KitaharaApplIntell2005" lang="en">
    <title>Pitch-dependent Identification of Musical Instrument Sounds</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle>Applied Intelligence</booktitle>
    <vol>23</vol>
    <no>3</no>
    <pp>267--275</pp>
    <month>12</month>
    <year>2005</year>
    <abst> This paper describes a musical instrument identification method that takes into
      consideration the <em>pitch dependency</em> of timbres of musical instruments. The difficulty
      in musical instrument identification resides in the pitch dependency of musical instrument
      sounds, that is, acoustic features of most musical instruments vary according to the pitch
      (fundamental frequency, F0). To cope with this difficulty, we propose an <em>F0-dependent
        multivariate normal distribution</em>, where each element of the mean vector is represented
      by a function of F0. Our method first extracts 129 features (e.g., the spectral centroid, the
      gradient of the straight line approximating the power envelope) from a musical instrument
      sound and then reduces the dimensionality of the feature space into 18 dimension. In the
      18-dimensional feature space, it calculates an <em>F0-dependent mean function</em> and an
        <em>F0-normalized covariance</em>, and finally applies the Bayes decision rule. Experimental
      results of identifying 6,247 solo tones of 19 musical instruments shows that the proposed
      method improved the recognition rate from 75.73% to 79.73%. </abst>
    <paperurl type="pdf">FY2005/AppliedIntelligence-2005-tetsu.pdf</paperurl>
  </item><item type="dc" id="KaijiriSI2005" lang="jp">
    <title>ロボットによる周囲状況把握のための雑音下での環境音認識</title>
    <authors>
      <author aff="KU-jp">海尻 聡</author>
      <author aff="KU-jp">石原 一志</author>
      <author idref="kitahara-jp"/>
      <author>Valin Jean-Marc</author>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle>計測自動制御学会 第6回システムインテグレーション部門講演会 (SI2005)</booktitle>
    <month>12</month>
    <year>2005</year>
  </item><item type="dc" id="ItoyamaIPSJNC2006" lang="jp">
    <title>多重奏中特定パートの自動採譜における複数特徴量の自動重み付け</title>
    <authors>
      <author aff="KU-jp">糸山 克寿</author>
      <author idref="kitahara-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2006"/>
    <series>2L-6</series>
    <month>3</month>
    <year>2006</year>
    <paperurl type="pdf">FY2005/ipsjnc-2006-itoyama.pdf</paperurl>
  </item><item type="dc" id="NishiyamaIPSJNC2006" lang="jp">
    <title>標題音楽アノテーションのための階層的物語タグの設計</title>
    <authors>
      <author aff="KU-jp">西山 正紘</author>
      <author idref="kitahara-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2006"/>
    <series>3L-6</series>
    <month>3</month>
    <year>2006</year>
    <paperurl type="pdf">FY2005/ipsjnc-2006-nisiyama.pdf</paperurl>
  </item><item type="dc" id="TaguchiIPSJNC2006" lang="jp">
    <title>擬音語表現を利用した環境音のためのXMLタグの設計と自動付与</title>
    <authors>
      <author aff="KU-jp">田口 明裕</author>
      <author idref="kitahara-jp"/>
      <author aff="KU-jp">石原 一志</author>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2006"/>
    <series>3L-7</series>
    <month>3</month>
    <year>2006</year>
    <paperurl type="pdf">FY2005/ipsjnc-2006-taguchi.pdf</paperurl>
  </item><item type="dc" id="KitaharaASJ2006s" lang="jp">
    <title>Instrogram：楽器存在確率に基づく音楽視覚表現法</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="asj2006s"/>
    <series>2-2-13</series>
    <month>3</month>
    <year>2006</year>
    <paperurl type="pdf">FY2005/asj-2006-tetsu.pdf</paperurl>
  </item><item type="dc" id="FujiharaASJ2006s" lang="jp">
    <title>調波構造抽出と高信頼度フレーム選択を用いた雑音下での話者識別</title>
    <authors>
      <author idref="fujihara-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="asj2006s"/>
    <series>1-11-17</series>
    <month>3</month>
    <year>2006</year>
    <paperurl type="pdf">FY2005/asj-2006-fujihara.pdf</paperurl>
  </item><item type="dr" id="MisawaWISS2005" lang="jp">
    <title>Openism：旋律補正に基づく演奏支援機能付き遠隔地セッションシステム</title>
    <authors>
      <author>三澤 由宇</author>
      <author>細野 裕</author>
      <author>仁科 章史</author>
      <author idref="ishida-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle idref="wiss2005"/>
    <month>12</month>
    <year>2005</year>
  </item><item type="dt" id="KitaharaSIGMUS2005" lang="jp">
    <title>振動機能付鍵盤楽器「ぶるぶるくん」を用いた即興演奏支援システム</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="ishida-jp"/>
      <author idref="takeda-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2005-MUS-60-5</series>
    <vol>2005</vol>
    <no>45</no>
    <pp>25--30</pp>
    <month>5</month>
    <year>2005</year>
    <slideurl type="pdf">FY2005/SIGMUS-2005-tetsu.pdf</slideurl>
  </item><item type="dc" id="KitaharaASJ2005" lang="jp">
    <title>混合音からの特徴量テンプレート作成と音楽的文脈の利用による多重奏の音源同定</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="asj2005a"/>
    <series>3-10-15</series>
    <month>9</month>
    <year>2005</year>
    <slideurl type="pdf">FY2005/asj-2005-tetsu.pdf</slideurl>
  </item><item type="ic" id="KitaharaICASSP2006" lang="en">
    <title>Instrogram: A New Musical Instrument Recognition Technique without Using Onset Detection
      nor F0 Estimation</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto2-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="icassp2006"/>
    <vol>V</vol>
    <pp>229--232</pp>
    <month>5</month>
    <year>2006</year>
    <abst> This paper describes a new technique for recognizing musical instruments in polyphonic
      music. Because the conventional framework for musical instrument recognition in polyphonic
      music had to estimate the onset time and fundamental frequency (F0) of each note, instrument
      recognition strictly suffered from errors of onset detection and F0 estimation. Unlike such a
      note-based processing framework, our technique calculates the temporal trajectory of
        <em>instrument existence probabilities</em> for every possible F0, and the results are
      visualized with a spectrogram-like graphical representation called <em>instrogram</em>. The
      instrument existence probability is defined as the product of a <em>nonspecific instrument
        existence probability</em> calculated using PreFEst and a <em>conditional instrument
        existence probability</em> calculated using the hidden Markov model. Experimental results
      show that the obtained instrograms reflect the actual instrumentations and facilitate
      instrument recognition. </abst>
    <paperurl type="pdf">FY2006/icassp-2006-tetsu.pdf</paperurl>
    <posterurl type="pdf">FY2006/icassp-2006-tetsu.pdf</posterurl>
    <award>IEEE関西支部 第3回学生研究奨励賞 受賞</award>
  </item><item type="ic" id="FujiharaICASSP2006" lang="en">
    <title>F0 Estimation Method for Singing Voice in Polyphonic Audio Signal based on Statistical
      Vocal Model and Viterbi Search</title>
    <authors>
      <author idref="fujihara-en"/>
      <author idref="kitahara-en"/>
      <author idref="goto2-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="icassp2006"/>
    <vol>V</vol>
    <pp>253--256</pp>
    <month>5</month>
    <year>2006</year>
  </item><item type="jj" id="FujiharaIPSJ2006" lang="jp">
    <title>伴奏音抑制と高信頼度フレーム選択に基づく楽曲の歌手名同定手法</title>
    <authors>
      <author idref="fujihara-jp"/>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle>情報処理学会論文誌</booktitle>
    <series>特集「情報処理技術のフロンティア」</series>
    <vol>47</vol>
    <no>6</no>
    <pp>1831--1843</pp>
    <month>7</month>
    <year>2006</year>
    <abst>
      本論文では，実世界の音楽音響信号に対する歌手名の同定手法について述べる．歌手名の同定を行う際に大きな問題となるのは，混在する伴奏音の影響である．本論文ではこの問題を解決するため，伴奏音抑制と高信頼度フレーム選択の手法を提案する．前者では，優勢なメロディの調波構造を抽出し再合成することで，伴奏音の影響を低減させることができる．後者は，歌声と非歌声を表す2種類の混合正規分布を用いて，それぞれのフレームが歌声として信頼できるか否かを判定するものである．実験の結果，本手法によって，10歌手40曲に対して95%の識別率を達成し，本手法を用いない場合と比較して誤り率を約89%削減した．また，20歌手256曲に対する実験の結果，約93%の識別率を達成し，誤り率を約65%削減した． </abst>
    <paperurl type="pdf">FY2006/ipsj-2006-fujihara.pdf</paperurl>
  </item><item type="dt" id="KitaharaSIGMUS2006" lang="jp">
    <title>Instrogram: 発音時刻検出とF0推定の不要な楽器音認識手法</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2006-MUS-66</series>
    <vol>2006</vol>
    <no>90</no>
    <pp>69--76</pp>
    <month>8</month>
    <year>2006</year>
    <paperurl type="pdf">FY2006/SIGMUS-2006-tetsu.pdf</paperurl>
    <slideurl type="pdf">FY2006/SIGMUS-2006-tetsu.pdf</slideurl>
  </item><item type="ic" id="FujiharaICSLP2006" lang="en">
    <title>Speaker Identification under Noisy Environments by using Harmonic Structure Extraction
      and Reliable Frame Weighting</title>
    <authors>
      <author idref="fujihara-en"/>
      <author idref="kitahara-en"/>
      <author idref="goto2-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="icslp2006"/>
    <month>9</month>
    <year>2006</year>
  </item><item type="ic" id="ItoyamaISMIR2006" lang="en">
    <title>Automatic Feature Weighting in Automatic Transcription of Specified Part in Polyphonic
      Music</title>
    <authors>
      <author aff="KU-en">Katsutoshi Itoyama</author>
      <author idref="kitahara-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="ismir2006"/>
    <month>10</month>
    <year>2006</year>
  </item><item type="jj" id="KitaharaIEICE2006" lang="jp">
    <title>多重奏を対象とした音源同定： 混合音テンプレートを用いた音の重なりに頑健な特徴量の重みづけ および音楽的文脈の利用</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>

    <booktitle>電子情報通信学会論文誌</booktitle>
    <vol>J89-D</vol>
    <no>12</no>
    <pp>2721--2733</pp>
    <month>12</month>
    <year>2006</year>
    <abst> 本論文では，多重奏に対する音源同定において不可避な課題である 「音の重なりによる特徴変動」について新たな解決法を提案する．
      多重奏では複数の楽器が同時に発音するため，各々の周波数成分が 重なって干渉し，音響的特徴が変動する． 本研究では，混合音から抽出した学習データに対して，
      各特徴量のクラス内分散・クラス間分散比を求めることで， 周波数成分の重なりの影響の大きさを定量的に評価する． そして，線形判別分析を用いることで，
      これを最小化するように特徴量を重みづけした新たな特徴量軸を生成する． これにより，周波数成分の重なりの影響をできるだけ小さくした特徴空間が得られる．
      さらに，音楽的文脈を利用することで音源同定のさらなる高精度化を図る． 実楽器音データベースから作成した二〜四重奏の音響信号を用いた 実験により，二重奏では50.9%から84.1%へ，
      三重奏では46.1%から77.6%へ，四重奏では43.1%から72.3%へ 認識率の改善を得，本手法の有効性を確認した． </abst>
    <paperurl type="pdf">FY2006/ieice-2006-kitahara.pdf</paperurl>
  </item><item type="ij" id="KitaharaEURASIP2006" lang="en" selected="yes">
    <title>Instrument Identification in Polyphonic Music: Feature Weighting to Minimize Influence of
      Sound Overlaps</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto2-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle>EURASIP Journal on Advances in Signal Processing</booktitle>
    <series>Special Issue on Music Information Retrieval based on Signal Processing</series>
    <vol>2007</vol>
    <no>51979</no>
    <pp>1--15</pp>
    <year>2007</year>
    <abst> This paper provides a new solution to the problem of feature variations caused by the
      overlapping of sounds in instrument identification in polyphonic music. When multiple
      instruments simultaneously play, partials (harmonic components) of their sounds overlap and
      interfere, which makes the acoustic features different from those of monophonic sounds. To
      cope with this, we weight features based on how much they are affected by overlapping. First,
      we quantitatively evaluate the influence of overlapping on each feature as the ratio of the
      within-class variance to the between-class variance in the distribution of training data
      obtained from polyphonic sounds. Then, we generate feature axes using a weighted mixture that
      minimizes the influence via linear discriminant analysis. In addition, we improve instrument
      identification using musical context. Experimental results showed that the recognition rates
      using both feature weighting and musical context were 84.1% for duo, 77.6% for trio, and 72.3%
      for quartet; those without using either were 53.4, 49.6, and 46.5%, respectively. </abst>
    <paperurl type="pdf">FY2006/EURASIP-JASP-2007-tetsu.pdf</paperurl>
  </item><item type="ij" id="KitaharaIPSJ2007" lang="en" selected="yes">
    <title>Instrogram: Probabilistic Representation of Instrument Existence for Polyphonic Music</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto2-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle>IPSJ Journal</booktitle>
    <series>Special Issue on Convenient, Familiar Music Information Processing</series>
    <vol>48</vol>
    <no>1</no>
    <pp>214--226</pp>
    <month>1</month>
    <year>2007</year>
    <paperurl type="pdf">FY2006/ipsj-2007-kitahara.pdf</paperurl>
    <award>第3回IPSJ Digital Courier船井若手奨励賞</award>
    <note>also published in IPSJ Digital Courier Vol.3, No.1, pp.1--13</note>
  </item><item type="ic" id="KitaharaISM2006" lang="en">
    <title>Musical Instrument Recognizer ``Instrogram'' and Its Application to Music Retrieval based
      on Instrumentation Similarity</title>
    <authors>
      <author idref="kitahara-en"/>
      <author idref="goto2-en"/>
      <author idref="komatani-en"/>
      <author idref="ogata-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="ism2006"/>
    <pp>265--272</pp>
    <month>12</month>
    <year>2006</year>
    <slideurl type="pdf">FY2006/ism-2006-tetsu.pdf</slideurl>
  </item><item type="dc" id="KitaharaASJ2006a" lang="jp">
    <title>Instrogramを用いた類似楽曲検索</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="asj2006a"/>
    <series>2-7-1</series>
    <month>9</month>
    <year>2006</year>
    <slideurl type="pdf">FY2006/asj-2006atm-tetsu_nosound.pdf</slideurl>
  </item><item type="th" id="KitaharaPhDThesis" lang="en">
    <title>Computational Musical Instrument Recognition and Its Application to Content-based Music
      Information Retrieval</title>
    <authors>
      <author idref="kitahara-jp"/>
    </authors>
    <series>博士論文 京都大学大学院情報学研究科</series>
    <month>2</month>
    <year>2007</year>
    <slideurl type="pdf">FY2006/d-kochokai_kitahara.pdf</slideurl>
    <award>第2回京都大学総長賞受賞</award>
  </item><item type="dt" id="HamanakaSIGMUS2006" lang="jp">
    <title>デモンストレーション：若手による研究紹介III</title>
    <authors>
      <author>浜中 雅俊</author>
      <author>竹川 佳成</author>
      <author>橋田 朋子</author>
      <author>元川 洋一</author>
      <author>馬場 哲晃</author>
      <author>日暮 圭</author>
      <author> 中野 倫靖</author>
      <author>吉井 和佳</author>
      <author>松原 正樹</author>
      <author>梶 克彦</author>
      <author>北原 鉄朗</author>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2006-MUS-66-10</series>
    <vol>2006</vol>
    <no>90</no>
    <pp>55--61</pp>
    <month>8</month>
    <year>2006</year>
  </item><item type="dt" id="HamanakaSIGMUS2006b" lang="jp">
    <title>デモンストレーション：若手による研究紹介IV</title>
    <authors>
      <author>浜中 雅俊</author>
      <author>竹川 佳成</author>
      <author>岩井 憲一</author>
      <author>高橋 直也</author>
      <author> 中野 倫靖</author>
      <author>大石 康智</author>
      <author>糸山 克寿</author>
      <author>北原 鉄朗</author>
      <author>吉井 和佳</author>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2006-MUS-67-3</series>
    <vol>2006</vol>
    <no>113</no>
    <pp>9--14</pp>
    <month>10</month>
    <year>2006</year>
  </item><item type="dt" id="NishiyamaSIGMUS2007" lang="jp">
    <title>マルチメディアコンテンツにおける音楽と映像の調和度計算モデル</title>
    <authors>
      <author>西山 正紘</author>
      <author idref="kitahara-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2007-MUS-69</series>
    <vol>2007</vol>
    <no>15</no>
    <pp>31--36</pp>
    <month>2</month>
    <year>2007</year>
  </item><item type="dt" id="AbeMA2007" lang="jp">
    <title>撥弦の物理モデルを用いた音響信号からのパラメータ推定</title>
    <authors>
      <author>安部 武宏</author>
      <author idref="kitahara-jp"/>
      <author>糸山 克寿</author>
      <author>柳田 益造</author>
    </authors>
    <booktitle>日本音響学会音楽音響研究会資料</booktitle>
    <series>MA2006-91</series>
    <pp>35--40</pp>
    <month>3</month>
    <year>2007</year>
  </item><item type="dc" id="NishiyamaIPSJNC2007" lang="jp">
    <title>マルチメディアコンテンツにおける音楽と映像の調和に関する分析</title>
    <authors>
      <author>西山 正紘</author>
      <author idref="kitahara-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2008"/>
    <series>2N-6</series>
    <month>3</month>
    <year>2007</year>
  </item><item type="dc" id="ShimizuIPSJNC2007" lang="jp">
    <title>OnomaTree：擬音語と木構造を併用した環境音検索インターフェース</title>
    <authors>
      <author>清水 敬太</author>
      <author idref="kitahara-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle idref="ipsjnc2007"/>
    <series>3N-7</series>
    <month>3</month>
    <year>2007</year>
  </item><item type="dr" id="TotaniInteraction2008" lang="jp">
    <title>楽器構成に着目した楽曲サムネイルとプレイリスト生成機能つき音楽プレイヤー</title>
    <authors>
      <author>戸谷 直之</author>
      <author idref="kitahara2-jp"/>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle>インタラクション2008（インタラクティブ発表）</booktitle>
    <pp>173--174</pp>
    <month>3</month>
    <year>2008</year>
  </item><item type="dt" id="KitaharaInteraction2008" lang="jp">
    <title>演奏家型人形を利用した見えない演奏者の可視化の試み</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author>小林 一樹</author>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle>インタラクション2008（ポスター発表）</booktitle>
    <month>3</month>
    <year>2008</year>
  </item><item type="dt" id="KitaharaSIGMUS2007" lang="jp">
    <title>音楽情報科学研究のための共通データフォーマットの確立を目指して</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author>橋田 光代</author>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2006-MUS-66-12</series>
    <vol>2007</vol>
    <no>81</no>
    <pp>149--154</pp>
    <month>8</month>
    <year>2007</year>
    <slideurl type="pdf">FY2007/SIGMUS-2007-kitahara.pdf</slideurl>
  </item><item type="dt" id="KitaharaEC2007" lang="jp">
    <title>楽器音認識技術を用いた音楽の可視化</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author idref="goto2-jp"/>
      <author idref="okuno-jp"/>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle idref="ec2007"/>
    <pp>145--148</pp>
    <month>10</month>
    <year>2007</year>
    <slideurl type="pdf">FY2007/ec-2007-kitahara.pdf</slideurl>
  </item><item type="dt" id="TsuchihashiSIGMUS2008" lang="jp">
    <title>音響信号を対象としたベースラインからの音楽ジャンル解析</title>
    <authors>
      <author>土橋 佑亮</author>
      <author idref="kitahara2-jp"/>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle>情報処理学会 音楽情報科学/音声言語情報処理 研究報告</booktitle>
    <series>2008-MUS-74-38, 2008-MUS-SLP-70-38</series>
    <vol>2008</vol>
    <no>12</no>
    <pp>217--224</pp>
    <month>2</month>
    <year>2008</year>
  </item><item type="dt" id="KatsuraSIGMUS2008" lang="jp">
    <title>ベイジアンネットワークを用いたコード・ヴォイシング推定システム</title>
    <authors>
      <author>勝占 真規子</author>
      <author idref="kitahara2-jp"/>
      <author idref="katayose-jp"/>
      <author>長田 典子</author>
    </authors>
    <booktitle>情報処理学会 音楽情報科学/音声言語情報処理 研究報告</booktitle>

    <series>2008-MUS-74-29, 2008-MUS-SLP-70-29</series>
    <vol>2008</vol>
    <no>12</no>
    <pp>163--168</pp>
    <month>2</month>
    <year>2008</year>
  </item><item type="dt" id="FujitaSIGMUS2008" lang="jp">
    <title>アーティストの個性を表す音楽的特徴に関する一考察</title>
    <authors>
      <author>藤田 徹</author>
      <author idref="kitahara2-jp"/>
      <author idref="katayose-jp"/>
      <author>長田 典子</author>
    </authors>
    <booktitle>情報処理学会 音楽情報科学/音声言語情報処理 研究報告</booktitle>

    <series>2008-MUS-74-35, 2008-MUS-SLP-70-35</series>
    <vol>2008</vol>
    <no>12</no>
    <pp>199--204</pp>
    <month>2</month>
    <year>2008</year>
  </item><item type="dc" id="KitaharaASJ2007a" lang="jp">
    <title>音楽情報処理のための共通データフォーマットCrestMuseXML−全体構想と基本設計方針−</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author>橋田 光代</author>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle idref="asj2007a"/>
    <series>2-1-4</series>
    <month>9</month>
    <year>2007</year>
  </item><item type="dt" id="HashidaSIGMUS2007" lang="jp">
    <title>音楽演奏表情データベースCrestMusePEDB ver1.0の公開について</title>
    <authors>
      <author>橋田 光代</author>
      <author>松井 淑恵</author>
      <author idref="kitahara2-jp"/>
      <author>酒造 祐介</author>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2007-MUS-72-1</series>
    <vol>2007</vol>
    <no>102</no>
    <pp>1--6</pp>
    <month>10</month>
    <year>2007</year>
  </item><item type="dt" id="HirataSIGMUS2007" lang="jp">
    <title>新博士にょるパネルディスカッション1「博士への道のりと将来への夢」</title>
    <authors>
      <author>平田 圭二</author>
      <author>梶 克彦</author>
      <author>亀岡 弘和</author>
      <author idref="kitahara2-jp"/>
      <author>齋藤 毅</author>
      <author>武田 晴登</author>
      <author>橋田 光代</author>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2007-MUS-71-7</series>
    <vol>2007</vol>
    <no>81</no>
    <pp>39--42</pp>
    <month>8</month>
    <year>2007</year>
  </item><item type="iv">
    <title>新博士によるパネルディスカッション1「博士への道のりと将来への夢」</title>
    <booktitle>情報処理学会第71回音楽情報科学研究会</booktitle>
    <series>パネリスト</series>
    <month>8</month>
    <year>2007</year>
  </item><item type="dt" id="GotoSIGMUS2008" lang="jp">
    <title>パネルディスカッション「``音''研究の未来」</title>
    <authors>
      <author idref="goto2-jp"/>
      <author>亀岡 弘和</author>
      <author idref="kitahara2-jp"/>
      <author>平賀 譲</author>
      <author>緒方 淳</author>
      <author>戸田 智基</author>
    </authors>
    <booktitle>情報処理学会 音楽情報科学/音声言語情報処理 研究報告</booktitle>
    <series>2008-MUS-74-10, 2008-SLP-70-10</series>
    <vol>2008</vol>
    <no>12</no>
    <pp>57--58</pp>
    <month>2</month>
    <year>2008</year>
  </item><item type="iv">
    <title>パネルディスカッション「``音''研究の未来」</title>
    <booktitle>情報処理学会 音楽情報科学研究会・音声言語情報処理研究会 特別合同企画</booktitle>
    <series>パネリスト</series>
    <month>2</month>
    <year>2008</year>
  </item><item type="dc" id="KitaharaIEICE" lang="jp">
    <title>Instrogram：多重奏中の楽器構成に関する確率論的表現法</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author idref="goto2-jp"/>
      <author idref="okuno-jp"/>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle>電子情報通信学会2008年総合大会</booktitle>
    <series>AS-5-4</series>
    <month>3</month>
    <year>2008</year>
  </item><item type="dc" id="KazetaniIPSJNC2008" lang="jp">
    <title>確率文脈自由文法を用いた事例参照型自動作曲システム</title>
    <authors>
      <author>風谷 真志</author>
      <author idref="kitahara2-jp"/>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle idref="ipsjnc2008"/>
    <series>3X-3</series>
    <month>3</month>
    <year>2008</year>
  </item><item type="tr">
    <title>デジタル音楽配信のためのコンテンツ管理</title>
    <authors>
      <author>Francois Pachet（著）</author>
      <author>北原 鉄朗（訳）</author>
    </authors>
    <booktitle>Communications of the ACM 日本語版</booktitle>
    <vol>4</vol>
    <no>2</no>
    <pp>1--6</pp>
    <month>6</month>
    <year>2004</year>
  </item><item type="tr">
    <title>音楽情報検索</title>
    <authors>
      <author>Bryan Pardo（著）</author>
      <author>北原 鉄朗（訳）</author>
    </authors>
    <booktitle>Communications of the ACM 日本語版</booktitle>
    <vol>6</vol>
    <no>2</no>
    <pp>1--3</pp>
    <year>2007</year>
  </item><item type="tr">
    <title>Shazam 音楽認識サービス</title>
    <authors>
      <author>Avery Wang（著）</author>
      <author>北原 鉄朗（訳）</author>
    </authors>
    <booktitle>Communications of the ACM 日本語版</booktitle>
    <vol>6</vol>
    <no>2</no>
    <pp>17--21</pp>
    <year>2007</year>
  </item><item type="rv">
    <title>楽曲の特徴量抽出と検索技術</title>
    <authors>
      <author idref="okuno-jp"/>
      <author idref="kitahara-jp"/>
      <author>吉井 和佳</author>
    </authors>
    <booktitle>電気学会誌</booktitle>
    <series>特集「音響機器は進歩している」</series>
    <vol>127</vol>
    <no>7</no>
    <pp>417--420</pp>
    <month>7</month>
    <year>2007</year>
  </item><item type="op">
    <title>音高による音色変化と未知楽器の問題を考慮した楽器音の音源同定</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle>日本音響学会関西支部 第6回若手研究者交流研究発表会</booktitle>
    <month>12</month>
    <year>2003</year>
  </item><item type="op">
    <title>多重奏の音源同定における音の重なりに対する頑健性の改善</title>
    <authors>
      <author idref="kitahara-jp"/>
      <author idref="goto2-jp"/>
      <author idref="komatani-jp"/>
      <author idref="ogata-jp"/>
      <author idref="okuno-jp"/>
    </authors>
    <booktitle>日本音響学会関西支部 第8回若手研究者交流研究発表会</booktitle>
    <month>12</month>
    <year>2005</year>
    <award shortened="yes">若手奨励賞受賞</award>
  </item><item type="pt">
    <text>鍵盤楽器支援装置及び鍵盤楽器支援システム，特開2006-145681号（2006年6月8日），特願2004-333279（2004年11月17日），発明者：武田 正之，石田
      克久，北原 鉄朗．</text>
  </item><item type="pt">
    <text>楽器音認識方法，楽器アノテーション方法，及び楽曲検索方法，特願2006-058649号（2006年3月3日），特開2007-240552号（2007年9月20日），発明者：北原
      鉄朗，奥乃 博． </text>
  </item><item type="gr">
    <text>（財）C&amp;C振興財団 国際会議論文発表者助成 採択（IEA/AIE-2003での発表に対して）</text>
  </item><item type="gr">
    <text>（財）情報科学国際交流財団 研究者海外派遣助成 採択（ICME 2003での発表に対して）</text>
  </item><item type="gr">
    <text>（財）原総合知的通信システム基金 国際会議論文発表助成 採択（ICASSP 2004での発表に対して）</text>
  </item><item type="gr">
    <text>（財）電気通信普及財団 海外渡航旅費援助 採択（ISMIR 2005での発表に対して）</text>
  </item><item type="gr">
    <text>（財）立石科学技術振興財団 国際交流助成 採択（ICASSP 2006での発表に対して）</text>
  </item><item type="gr">
    <text>（財）電気通信普及財団 海外渡航旅費援助 採択（ISM 2008での発表に対して）</text>
  </item><item type="gr">
    <text>平成15年度 ASTEM学生ベンチャー奨励金制度 奨励金採択</text>
    <text>「即興演奏の不自然な旋律を自動的に補正する機能を組み込んだ電子楽器の開発」</text>
  </item><item type="gr">
    <text>平成16年度 SCAT研究奨励金 採択</text>
    <text>「音楽音響信号に対するMPEG-7タグの自動付与および音楽情報検索への応用」</text>
  </item><item type="gr">
    <text>21世紀COE「知識社会基盤構築のための情報学拠点形成」平成16年度 若手リーダーシップ養成プログラム研究費 採択</text>
    <text>「高度な音楽検索実現のための音楽音響信号に対するMPEG-7タグの自動付与」</text>
  </item><item type="gr">
    <text>日本学術振興会 科学研究費補助金 特別研究員研究奨励費（平成17～18年度）</text>
    <text>「音楽のディジタルアーカイブ化のためのMPEG-7タグの設計と自動付与」</text>
  </item><item type="gr">
    <text>日本学生支援機構 第1種奨学金「特に優れた業績による返還免除」認定（全額）</text>
  </item><item type="iv">
    <title>音楽の信号処理とパターン処理の基礎技術：入門と実践</title>
    <booktitle>情報処理学会 第76回音楽情報科学研究会 チュートリアル</booktitle>
    <series>講師</series>
    <month>8</month>
    <year>2008</year>
  </item><item type="iv">
    <title>CrestMuseXML Toolkitで始める音楽情報処理入門</title>
    <booktitle>情報処理学会 第80回音楽情報科学研究会 チュートリアル</booktitle>
    <series>講師</series>
    <month>5</month>
    <year>2009</year>
  </item><item type="ic" id="KitaharaICMPC2008a" lang="en">
    <title>Computational Model for Automatic Chord Voicing based on Bayesian Network</title>
    <authors>
      <author idref="kitahara2-en"/>
      <author>Makiko Katsura</author>
      <author idref="katayose-en"/>
      <author>Noriko Nagata</author>
    </authors>
    <booktitle idref="icmpc2008"/>
    <pp>395--398</pp>
    <month>8</month>
    <year>2008</year>
    <paperurl type="pdf">FY2008/icmpc-2008-kitahara-1.pdf</paperurl>
    <slideurl type="pdf">FY2008/icmpc-2008-katsura.pdf</slideurl>
  </item><item type="ic" id="KitaharaICMPC2008b" lang="en">
    <title>Computational Model of Congruency between Music and Video</title>
    <authors>
      <author idref="kitahara2-en"/>
      <author>Masahiro Nishiyama</author>
      <author idref="okuno-en"/>
    </authors>
    <booktitle idref="icmpc2008"/>
    <month>8</month>
    <year>2008</year>
    <posterurl type="pdf">FY2008/icmpc-2008-nisiyama.pdf</posterurl>
    <note>abstract only</note>
  </item><item type="ic" id="HashidaICMPC2008" lang="en">
    <title>Rencon: Performance Rendering Contest for Automated Music Systems</title>
    <authors>
      <author>Mitsuyo Hashida</author>
      <author>Teresa M. Nakra</author>
      <author>Haruhiro Katayose</author>
      <author>Tadahiro Murao</author>
      <author>Keiji Hirata</author>
      <author>Kenji Suzuki</author>
      <author idref="kitahara2-en"/>
    </authors>
    <booktitle idref="icmpc2008"/>
    <pp>53--57</pp>
    <month>8</month>
    <year>2008</year>
    <paperurl type="pdf">FY2008/icmpc-2008-hashida.pdf</paperurl>
  </item><item type="ic" id="TsuchihashiISMIR2008" lang="en">
    <title>Using Bass-line Features for Content-based MIR</title>
    <authors>
      <author>Yusuke Tsuchihashi</author>
      <author idref="kitahara2-en"/>
      <author idref="katayose-en"/>
    </authors>
    <booktitle idref="ismir2008"/>
    <pp>620--625</pp>
    <month>9</month>
    <year>2008</year>
    <paperurl type="pdf">FY2008/ismir-2008-tsuchihashi.pdf</paperurl>
    <posterurl type="pdf">FY2008/ismir-2008-tsuchihashi.pdf</posterurl>
  </item><item type="ic" id="KitaharaMASP2008" lang="en">
    <title>Music Genre Classification and Similarity Calculation Using Bass-line Features</title>
    <authors>
      <author idref="kitahara2-en"/>
      <author>Yusuke Tsuchihashi</author>
      <author idref="katayose-en"/>
    </authors>
    <booktitle idref="masp2008"/>
    <pp>574--579</pp>
    <month>12</month>
    <year>2008</year>
    <slideurl type="pdf">FY2008/masp-2008-kitahara.pdf</slideurl>
  </item><item type="dt" id="KitaharaSIGMUS2008" lang="jp">
    <title>CrestMuseXML (CMX) Toolkit ver.0.40について</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2008-MUS-75-17</series>
    <vol>2008 </vol>
    <no>50</no>
    <pp>95--100</pp>
    <month>5</month>
    <year>2008</year>
    <paperurl type="pdf">FY2008/SIGMUS-2008-kitahara.pdf</paperurl>
  </item><item type="dt" id="KitaharaSIGMUS2008panel" lang="jp">
    <title>新博士によるパネルディスカッションII「楽しくさせる音楽，楽しくさせる研究」</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author>平田 圭二</author>
      <author>竹川 佳成</author>
      <author>中野 倫靖</author>
      <author>森勢 将雅</author>
      <author>吉井 和佳</author>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2008-MUS-76-1</series>
    <vol>2008 </vol>
    <no>78</no>
    <pp>1--4</pp>
    <month>8</month>
    <year>2008</year>
  </item><item type="dt" id="HashimotoSIGMUS2008" lang="jp">
    <title>音楽音響信号を対象とした指揮演奏システム：フェルマータ時における打楽器音抑制とスケジューラの検討</title>
    <authors>
      <author>橋本 祐輔</author>
      <author idref="kitahara2-jp"/>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2008-MUS-76-7</series>
    <vol>2008 </vol>
    <no>78</no>
    <pp>33--37</pp>
    <month>8</month>
    <year>2008</year>
  </item><item type="dc" id="KitaharaASJ2008" lang="jp">
    <title>MIDIデータのベロシティを異なる音源に適応させる試み</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author idref="katayose-jp"/>
    </authors>
    <booktitle idref="asj2008a"/>
    <series>1-9-16</series>
    <month>9</month>
    <year>2008</year>
    <slideurl type="pdf">FY2008/asj-2008atm-kitahara.pdf</slideurl>
  </item><item type="dc" id="KobayashiJSAI2008" lang="jp">
    <title>効率的なロボットプログラミング環境の実現に向けて</title>
    <authors>
      <author>小林 一樹</author>
      <author idref="kitahara2-jp"/>
    </authors>
    <booktitle idref="jsai2008"/>
    <series>2G1-1</series>
    <month>5</month>
    <year>2008</year>
  </item><item type="dt" id="MiuraSIGMUS2008" lang="jp">
    <title>パネルディスカッション：作るだけでいいの？調べるだけでいいの？</title>
    <authors>
      <author>三浦 雅展</author>
      <author>江村 伯夫</author>
      <author idref="kitahara2-jp"/>
      <author>若槻 尚斗</author>
      <author>藤島 琢哉</author>
      <author>西口 磯春</author>
      <author>平田 圭二</author>
      <author>柳田 益造</author>
      <author>後藤 真孝</author>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2008-MUS-78-11</series>
    <vol>2008</vol>
    <no>78</no>
    <pp>59--66</pp>
    <month>12</month>
    <year>2008</year>
  </item><item type="iv">
    <title>パネルディスカッション：作るだけでいいの？調べるだけでいいの？</title>
    <booktitle>情報処理学会第78回音楽情報科学研究会・日本音響学会音楽音響研究会 合同特別企画</booktitle>
    <series>パネリスト</series>
    <month>12</month>
    <year>2008</year>
  </item><item type="dt" id="HashidaSIGMUS2008" lang="jp">
    <title>演奏表情付けコンテストICMPC-Rencon開催報告</title>
    <authors>
      <author>橋田 光代</author>
      <author>片寄 晴弘</author>
      <author>平田 圭二</author>
      <author idref="kitahara2-jp"/>
      <author>鈴木 健嗣</author>
    </authors>
    <booktitle idref="sigmus"/>
    <series>2008-MUS-78-12</series>
    <vol>2008</vol>
    <no>78</no>
    <pp>67--72</pp>
    <month>12</month>
    <year>2008</year>
  </item><item type="jj" id="KitaharaIPSJ2009" lang="jp">
    <title>ベイジアンネットワークを用いた自動コードヴォイシングシステム</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author>勝占 真規子</author>
      <author>片寄 晴弘</author>
      <author>長田 典子</author>
    </authors>
    <booktitle>情報処理学会論文誌</booktitle>
    <series>特集「音楽情報処理」</series>
    <vol>50</vol>
    <no>3</no>
    <pp>1067--1078</pp>
    <month>3</month>
    <year>2009</year>
    <paperurl type="pdf">FY2008/ipsj-2009-kitahara.pdf</paperurl>

  </item><item type="dr" id="KitaharaInteraction2009" lang="jp">
    <title>BayesianBand：旋律の予測に基づいた自動伴奏システム</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author>徳網 亮輔</author>
      <author>戸谷 直之</author>
      <author>橋本 寿政</author>
      <author>片寄 晴弘</author>
    </authors>
    <booktitle>インタラクション2009（インタラクティブ発表）</booktitle>



    <pp>31--32</pp>
    <month>3</month>
    <year>2009</year>
    <paperurl type="pdf">FY2008/interaction-2009-kitahara.pdf</paperurl>

  </item><item type="rv" id="KitaharaDTMM2009" lang="jp">
    <title>音楽情報処理最前線！ 楽器で音楽が探せる 「楽器認識技術」が叶える音楽の新しい聴き方・探し方</title>
    <authors>
      <author idref="kitahara2-jp"/>
    </authors>
    <booktitle>DTM Magazine</booktitle>
    <vol>176</vol>
    <pp>102--103</pp>
    <month>2</month>
    <year>2009</year>
  </item><item type="jj" id="HashidaIPSJ009" lang="jp">
    <title>ピアノ名演奏の演奏表現情報と音楽構造情報を対象とした音楽演奏表情データベースCrestMusePEDBの構築</title>
    <authors>
      <author>橋田 光代</author>
      <author>松井 淑恵</author>
      <author idref="kitahara2-jp"/>
      <author>片寄 晴弘</author>
    </authors>
    <booktitle>情報処理学会論文誌</booktitle>
    <series>特集「音楽情報処理」</series>
    <vol>50</vol>
    <no>3</no>
    <pp>1090--1099</pp>
    <month>3</month>
    <year>2009</year>
  </item><item type="dt" id="KitaharaSIGMUS2009" lang="jp">
    <title>CrestMuseXML Toolkitで始める音楽情報処理入門</title>
    <authors>
      <author idref="kitahara2-jp"/>
    </authors>
    <booktitle>情報処理学会 音楽情報科学 研究報告</booktitle>
    <series>2009-MUS-50-1</series>
    <month>5</month>
    <year>2009</year>
    <slideurl type="pdf">FY2009/SIGMUS-2009-kitahara-tutorial.pdf</slideurl>
  </item><item type="lt" id="KitaharaIPSJ2009b" lang="jp">
    <title>BayesianBand：ユーザとシステムが相互に予測し合うジャムセッションシステム</title>
    <authors>
      <author idref="kitahara2-jp"/>
      <author>戸谷 直之</author>

      <author>徳網 亮輔</author>
      <author>片寄 晴弘</author>
    </authors>
    <booktitle>情報処理学会論文誌（テクニカルノート）</booktitle>
    <series>特集「エンターテインメントコンピューティング」</series>
    <vol>50</vol>
    <no>12</no>
    <pp>2949--2953</pp>
    <month>12</month>
    <year>2010</year>
  </item><item type="ic" id="KitaharaICEC2009" lang="en">
    <title>BayesianBand: Jam Session System based on Mutual Prediction by User and System</title>
    <authors>
      <author idref="kitahara2-en"/>
      <author>Naoyuki Totani</author>
      <author>Ryosuke Tokuami</author>
      <author>Haruhiro Katayose</author>
    </authors>
    <booktitle>Entertainment Computing: Proceedings of the 10th International Conference on
    Entertainment Computing (ICEC 2009)</booktitle>
    <pp>179--184</pp>
    <month>9</month>
    <year>2009</year>
    <slideurl type="pdf">FY2009/ieice-2009-kitahara.pdf</slideurl>
  </item><item type="dt" id="TotaniEC2009" lang="jp">
  <title>予測型ジャムセッションシステムBayesianBandにおける可視化機能の導入</title>
  <authors>
    <author>戸谷 直之</author>
    <author idref="kitahara2-jp"/>
    <author>片寄 晴弘</author>
  </authors>
  <booktitle>エンターテインメントコンピューティング2009</booktitle>
  <month>9</month>
  <year>2009</year>
</item><item type="dt" id="HashidaEC2009" lang="jp">
   <title>演奏表情付けコンテストEC-Rencon</title>
   <authors>
     <author>橋田 光代</author>
     <author idref="kitahara2-jp"/>
     <author>鈴木健嗣</author>
     <author>平田 圭二</author>
     <author>片寄 晴弘</author>
   </authors>
   <booktitle>エンターテインメントコンピューティング2009</booktitle>
   <month>9</month>
   <year>2009</year>
 </item><item type="ij" id="FujiharaASLP2009" lang="en">
    <title>Singing Voice Representation Robust to Accompaniment Sounds and Its Application to Singer
      Identification and Vocal-timbre-similarity-based Music Information Retrieval</title>
    <authors>
      <author>Hiromasa Fujihara</author>
      <author idref="goto2-en"/>
      <author idref="kitahara2-en"/>
      <author idref="okuno-en"/>
    </authors>
    <booktitle>IEEE Transaction on Audio, Speech, and Language Processing</booktitle>
    <series>Special Issue on Signal Models and Representation of Musical and Environmental Sounds</series>
    <vol>18</vol>
    <no>3</no>
    <pp>638--648</pp>
    <month>3</month>
    <year>2010</year>
  </item><item type="rv" id="HiraiIPSJ2009" lang="jp">
    <title>音楽とヒューマンインタフェース</title>
    <authors>
      <author>平井 重行</author>
      <author>橋田 光代</author>
      <author idref="kitahara2-jp"/>
      <author>竹川 佳成</author>
      <author>片寄 晴弘</author>
    </authors>
    <booktitle>情報処理</booktitle>
    <series>特集「音楽処理技術の最前線」</series>
    <vol>50</vol>
    <no>8</no>
    <pp>756--763</pp>
    <month>8</month>
    <year>2009</year>
  </item><item type="rv" id="KitaharaJSAI2009" lang="jp">
    <title>私のブックマーク「音楽情報処理」</title>
    <authors>
      <author idref="kitahara2-jp"/>
    </authors>
    <booktitle>人工知能学会誌</booktitle>
    <vol>24</vol>
    <no>5</no>
    <pp>921--929</pp>
    <month>11</month>
    <year>2009</year>
  </item><item type="bc" id="KitaharaAMIR2010" lang="en">
    <title>Mid-level Representations of Musical Audio Signals for Music Information Retrieval</title>
    <authors>
      <author idref="kitahara2-en"/></authors>
    <booktitle>Advances in Music Information Retrieval</booktitle>
    <series>Studies in Computational Intelligence 274</series>
    <eds>Zbigniew W. Ras and Alicja A. Wieczorkowska</eds>
    <pub>Springer</pub>
    <month>2</month>
    <year>2010</year>
  </item><item type="dc" id="YamakawaIPSJNC2010" lang="jp">
    <title>環境音から擬音語への自動変換における特徴量抽出法の検討</title>
  <authors><author>山川 暢英</author><author idref="kitahara2-jp"/><author>高橋 徹</author><author>駒谷 和範</author><author>尾形 哲也</author><author>奥乃 博</author></authors><booktitle>情報処理学会第72回全国大会</booktitle><series>3U-9</series><month>3</month><year>2010</year></item><item type="dc" id="MizumotoIPSJNC2010" lang="jp">
    <title>エレキギターにおける演奏情報の特徴抽出</title>
  <authors><author>水本 直希</author><author idref="kitahara2-jp"/><author>片寄 晴弘</author></authors><booktitle>情報処理学会第72回全国大会</booktitle><series>5T-1</series><month>3</month><year>2010</year></item><item type="dc" id="SuguruIPSJNC2010" lang="jp">
    <title>奄美大島民謡風歌声合成のためのコブシに着目した歌声の特徴分析</title>
  <authors><author>村主 大輔</author><author>森勢 将雅</author><author idref="kitahara2-jp"/> <author>片寄 晴弘</author></authors><booktitle>情報処理学会第72回全国大会</booktitle><series>6U-4</series><month>3</month><year>2010</year></item><item id="HashidaSIGMUS2009" type="dt">
  <title>演奏表情付けコンテストEC-Rencon開催報告</title>
  <authors>
    <author>橋田 光代</author>
    <author idref="kitahara2-jp"/>
    <author>鈴木 健嗣</author>
    <author>片寄 晴弘</author>
    <author>平田 圭二</author>
  </authors>
  <booktitle>情報処理学会 音楽情報科学 研究報告</booktitle>
  <series>2009-MUS-83</series>
  <month>11</month>
  <year>2009</year>
</item>
  <xi:include href="paperlist.xml" xpointer="xpointer(/paperlist/item)" parse="xml"/>
  <item type="sc">
    <text>情報処理学会 音楽情報科学研究会 主査（2015年度〜2016年度）</text>
  </item><item type="sc">
    <text>2016年度人工知能学会全国大会（第30回） 大会委員</text>
  </item><item type="sc">
    <text>Special Session on Music Information Processing, the IEEE 8th International Conference on Knowledge and Systems Engineering (KSE 2016), Session Organier</text>
  </item><item type="sc">
    <text>情報処理学会論文誌「エンターテインメントコンピューティング」特集（2016年12月発行予定）編集委員会 編集委員</text>
  </item><item type="sc">
    <text>情報処理学会誌「音楽を軸に拡がる情報科学」特集（2016年6月号）ゲストエディタ</text>
  </item><item type="sc">
    <text>情報処理学会論文誌「音楽情報処理技術の進歩とその拡がり」特集（2016年5月号）編集委員会 幹事</text>
  </item><item type="sc">
    <text>2015年度人工知能学会全国大会（第29回） 大会委員</text>
  </item><item type="sc">
    <text>情報処理学会 第76回全国大会 プログラム編成WG 委員</text>
  </item><item type="sc">
    <text>情報処理学会／電子情報通信学会 第13回情報科学技術フォーラム（FIT 2014） プログラム委員会 委員</text>
  </item><item type="sc">
    <text>Special Session on Hot Topics in Music Information Processing, the 12th IEEE International Conference on Signal Processing, Session Co-organizer</text>
  </item><item type="sc">
    <text>日本音響学会2014年春季研究発表会 実行委員</text>
  </item><item type="sc">
    <text>情報処理学会／電子情報通信学会 第12回情報科学技術フォーラム（FIT 2013） 研究会担当委員</text>
  </item><item type="sc">
    <text>情報処理学会論文誌「音楽情報処理の新展開（音楽情報科学研究会20周年記念特集）」特集（2013年4月号）編集委員会 編集委員</text>
  </item><item type="sc">
    <text>情報処理学会 音楽情報科学研究会 幹事（2011年度〜2014年度）</text>
  </item><item type="sc">
    <text>電子情報通信学会 和文論文誌D 編集委員会 編集委員（2011年度〜2014年度）</text>
  </item><item type="sc">
    <text>情報処理学会 音楽情報科学研究会 運営委員（2007年度～2010年度）</text>
  </item><item type="sc">
    <text>ISMIR 2009, Local Organizing Committee Chair</text>
  </item><item type="sc">
    <text>科学技術新興機構デジタルメディア領域主催シンポジウム「表現の未来へ」推進委員（2007年度）</text>
  </item><item type="sc">
    <text>ピアノ演奏表情付けコンテスト「Rencon」Committee Member （2007年度〜2011年度）</text>
  </item><item type="sc">
    <text>論文誌査読（複数回）：情報処理学会論文誌，電子情報通信学会論文誌，日本音響学会誌, 人工知能学会論文誌, IEEE Transactions on Acoustics, Speech, and Language, IEEE Journal of Selected Topics in Signal Processing, 芸術科学会, ヒューマンインタフェース学会</text>
  </item><item type="sc">
    <text>論文誌査読（1回のみ）：Journal of New Music Research, Signal Processing，日本神経回路学会誌</text>
  </item><item type="sc">
    <text>国際会議論文査読：ISMIR 2007, WASPAA 2007, ISMIR 2008, ISMIR 2009, ISMIR 2010, SAPA 2010, ISMIR 2011, ACE 2015, ACE 2016, IEEE-KSE 2016</text>
  </item><item type="sc">
    <text>国内会議論文査読：FIT 2008, FIT 2009</text>
  </item>

</paperlist>
